<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Demography and Data Science</title>
    <meta charset="utf-8" />
    <meta name="author" content="Connor Gilroy Copyright (c) 2021 Connor Gilroy (MIT Licensed)" />
    <meta name="date" content="2021-05-24" />
    <script src="libs/header-attrs-2.7/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/presentation-styles.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Demography and Data Science
##  
### Connor Gilroy<br>Copyright (c) 2021 Connor Gilroy (<a href="https://github.com/ccgilroy/demography-and-data-science/blob/master/LICENSE">MIT Licensed</a>)
### 2021-05-24

---


# About me

.font90[

- Sixth-year PhD student in Sociology

- All of my research projects have involved digital data or data science in some form— 

  - **The Fragile Families Challenge:** A machine-learning competition on the FFCWS data had less amazing results than you might hope, but we learned some interesting things about surveys and prediction
  
  - **Sexuality disclosure on Facebook:** "Reach" estimates from Facebook's advertising platform can show how the salience of sexual identity varies in the United States
  
  - **Gayborhood change:** I webscraped and geocoded an old digital archive of gay bars to identify gay neighborhoods and examine how those places change over time
  
  - **The meaning of "community":** Using word embeddings, I'm disentangling analytical dimensions of "community" from everyday language, with the aim of constructing a new text-based measure for the experience of a sense of community
  
  - **Networks of homeless care organizations:** With Twitter networks, we're measuring connections between geographically dispersed local homeless care organizations, to see how those ties relate to federal funding and measures of efficacy

- **Contact info:** [cgilroy@uw.edu](mailto:cgilroy@uw.edu), [@ccgilroy](https://twitter.com/ccgilroy) on Twitter, [website](https://students.washington.edu/cgilroy/)

]

---

# Outline

### Monday

- Overview of demography and data science
  - A sociological example from a paper of mine
  
### Wednesday

- Interactive demo of webscraping and API use

### Friday 

Open-ended, with a few potential directions depending on your interests and needs:

- [My tutorial on the tidycensus package](https://csde-uw.github.io/tidycensus-tutorial/)
- The text analysis portion of [Monica Alexander's workshop materials](https://mjalexander.github.io/social_media_workshop/)
- A walkthrough of the code for published or in-progress research
- Something further afield from demography, like [my materials on word embeddings](https://ccgilroy.github.io/word-embeddings-workshop/)

---

# Demography and the data revolution

Emilio Zagheni (MPIDR) makes the argument that demography has been "data-driven" going back to John Graunt in the 16th century ... 

.center[![source: MPIDR website](img/emilio.jpg)]

... so it's not a surprise that demographers might be interested in new, digital sources of data.

.right[[Alburez-Gutierrez et al 2019]]

---

# Motivating examples

1. **Migration:** more current and transnationally consistent data about migrants

  .center[&lt;img src="img/puerto_rico.png" style="width: 50%" /&gt;]
  
  .right[[Alexander et al 2019]]

2. **Residential mobility and segregation:** more detailed and accurate data about people's mobility, exposure, and opportunities

.right[[+ a few other topics]]

---

# Migration 

Digital data are especially useful for studying short-term or recent migration in response to shocks, before they've appeared in official statistics. Examples:

- out-migration from Puerto Rico after Hurricane María, using Facebook ads data (Alexander et al 2019) ([GitHub](https://github.com/MJAlexander/fb-migration-hurricane-maria))
- migrant flows from Venezuela in response to the humanitarian and economic crisis there, using geolocated Twitter data (Mazzoli et al 2020)

**Non-representativeness** is a major issue. Some of the most relevant statistical challenges are around validating these data against and combining them with other data sources. Recent work has started to address those challenges directly: 

- [MPIDR working paper](https://www.demogr.mpg.de/papers/working/wp-2020-019.pdf) (Hsiao et al 2020) combining Twitter and ACS data
- [Alexander et al 2020](https://doi.org/10.1007/s11113-020-09599-3), combining Facebook ads and ACS data ([GitHub](https://github.com/MJAlexander/fb-migration-bayes))

---

# Migration 

### Alexander, Polimis, and Zagheni 2020

.center[&lt;img src="img/alexander_model.png" style="width: 50%"/&gt;]

.center[Link to code: https://github.com/MJAlexander/fb-migration-bayes]

---

# Residential mobility and segregation

Phillips et al (2019) argue that geolocated Twitter data provide a more accurate measure of connectedness between neighborhoods based on mobility patterns, and thus a better measure of metro-level integration than measures of residential segregation alone. 

.center[&lt;img src="img/networks.png" style="width: 50%" /&gt;]

Hess and Chasins (working paper, n.d.) scrape data from Craigslist to examine variation in Seattle rental markets. [Kennedy et al 2020](https://doi.org/10.1093/sf/soaa075) use these same data to investigate how the *text* of these listings varies by the racial composition of neighborhoods.

---

# Other examples

### On-platform surveys

Dennis Feehan (Berkeley Demography) administers surveys on Facebook to learn about offline populations (Feehan and Cobb 2019)

.center[&lt;img src="img/meal.png" style="width: 30%" /&gt;]

Much covid-related research in the past year, including the [Facebook/CMU/UMD Covid-19 Symptom Survey](https://dataforgood.fb.com/docs/covid-19-symptom-survey-request-for-data-access/), follows similar principles; Facebook releases some other aggregate data through their Data for Good program

### Google search

Ridhi Kashyap et al (conference paper, 2017) use Google searches to "now-cast" sex ratios at birth in India; Bail et al 2019 also use Google search data for a sociological paper on diffusion

---

# Different kinds of data

### individual trace data

- geolocated tweets
- friend and follower ties
- mobile phone records
- Craigslist listings
- ...

### aggregate counts

- Facebook ads reach estimates
- Twitter account metadata (e.g. number of followers)
- derived estimates from individual data (which might be lower-risk to share)
- ...

---

# Ethics and other considerations

- IRBs don't consider most projects collecting digital trace data to be human subjects research

- But people aren't always comfortable being "participants" in e.g. Twitter research (Fiesler and Proferes 2018). They object less to aggregate data than to picking out individual users. (*Definitely* don't quote tweets verbatim in papers or presentations, for example!)

- It's also good to be aware of corporate policies and terms of service (TOS) for the websites and platforms you might use. But violating TOS may be warranted in some cases (see the court case [*Sandvig v Barr*](https://www.aclu.org/press-releases/federal-court-rules-big-data-discrimination-studies-do-not-violate-federal-anti))

- There's a certain strain of research that attempts to infer demographic characteristics (gender, race, age, even sexual orientation) from social media users' names, faces, or behaviors. There are strong critiques of this work, and I wouldn't recommend doing it. 

---

class: inverse, center, middle

# Question break

---

# Methods

*How do you gain access to demographic digital trace data?*

Two broad options, which boil down to: 

1. Convince someone else to give the data to you

2. Get the data yourself

---

# Convincing someone

This means collaborating directly with the corporations that collect, store, and own the data. 

Corporate collaborations are high risk, high reward, and require lots of economic or social capital. Examples: 

- [Social Science One](https://socialscience.one/our-facebook-partnership), a partnership between Facebook and a Harvard research team led by Gary King

- Some kinds of data, like **mobile phone** data, are only available through this sort of collaborative agreement (for good reason!)

- The same is true for **online dating** data ([Elizabeth Bruch's work](https://mhbsd.net/research/), for example)

As a graduate student, you probably can't do this, unless you find a faculty PI who already has some kind of agreement or access. 

---

# Getting the data yourself

*What **can** a graduate student do?*

### the "wild west" of webscraping

Web pages are written in HTML and CSS, which give them structure. 

Researchers can "scrape" particular elements from web pages with code; if many pages have the same structure, we can build a data set this way.

### the era of APIs

Web application programming interfaces (APIs) are a structured way for computers to talk to each other. They're how your web browser gets a web page in the first place.

Researchers can do this too: make a request (with the right parameters), get a response back (hopefully with data). Many major websites have public-facing APIs that researchers can use.

---

# The end of an era?

Freelon (2018) argues that we've entered the **"post-API age"**, as large companies like Facebook have clamped down on public access:

&gt; The closure of the Pages API eliminated all terms of service (TOS)-compliant access to Facebook content. Let me underscore the magnitude of this shift: There is currently no way to independently extract content from Facebook without violating its TOS.  
&gt;  
&gt; At the flip of a metaphorical switch, Facebook instantly invalidated all methods that depended on the Pages API. For example, I gave a Facebook data collection workshop in January 2018 at the University of Michigan whose lessons are now mostly unusable....

One consequence is that webscraping is making a comeback

---

# Maybe don't give up on APIs yet

### Twitter Academic API

In January 2021, [Twitter announced](https://blog.twitter.com/developer/en_us/topics/tools/2021/enabling-the-future-of-academic-research-with-the-twitter-api.html) a new API track which academic researchers can apply for, which provides greater access in terms of volume and historical data. If you have a specific research project and are affiliated with a university, this opens up new possibilities. (The Academic API is for research only, not teaching.)

### Other platforms

- **Pushshift.io** primarily provides API access to data from Reddit, useful for studying the behavior of individuals in online communities

- **Crowdtangle** remains restricted-access, but provides limited information on public Facebook pages, groups, and profiles

---

# Computational social science 

Outside demography, there's CSS research on culture, ideology, polarization, and many other topics

- in **political science** 
  - Rochelle Terman // https://plsc-31101.github.io/course/
  - Pablo Barberá // http://pablobarbera.com/POIR613/

- in **sociology** 
  - Matt Salganik &amp; Chris Bail // SICSS
  - Kieran Healy // http://socviz.co/
  
CSS methods that haven't seen much use yet in demography include **crowdsourcing** and **text as data** (though see Kennedy et al 2020)

---

class: inverse, center, middle

# Question break

---

# Example

### Social media disclosure and the salience of sexual identity

Ridhi Kashyap and I have a paper using Facebook ads estimates to examine the disclosure of sexual orientation / sexual identity in the US

- This project started as a demographic estimates paper, but we ultimately shifted toward a more sociological interpretation of the data 

We used stratified queries to build a four-way contingency table - *sexuality X gender X relationship status X age* - then fit a loglinear model to that table

- Specifically, we fit a Bayesian negative binomial model using **rstanarm**; we model *age* with a continuous polynomial rather than age bins (you'll see why in a moment)
- Model comparison might have shown that some of these four characteristics were conditionally independent of each other; instead, we found out that all of these factors are interrelated 
  - Most of the paper focuses on carefully going through and interpreting those associations 

---
class: inverse, center, middle

# 

![](img/figure2_disclosure.png)

---
class: inverse, center, middle


# 

.image-90[![](img/figure7_model_estimates.png)]

---
class: inverse, center, middle

# 

.image-90[![](img/figure8_data_estimates.png)]

---

# Demo (Wednesday)

Before Wednesday, create a Twitter account if you don't have one and install these packages:


```r
library(tidyverse) # general R data science tools
library(rvest) # for web scraping
library(httr) # for general API access
library(jsonlite) # for working with json-formatted responses
library(rtweet) # for Twitter API access
library(leaflet) # for maps
```

Download the demo code from https://github.com/ccgilroy/csss563-demo

You can view a static  version of the demo at https://ccgilroy.github.io/csss563-demo/demo.html

---

# References and further reading

.font60.pull-left[
Alburez-Gutierrez, Diego, Emilio Zagheni, Samin Aref, Sofia Gil-Clavel, André Grow, and Daniela Veronica Negraia. 2019. Demography in the Digital Era: New Data Sources for Population Research. preprint. SocArXiv.  

Alexander, Monica, Kivan Polimis, and Emilio Zagheni. 2019. “The Impact of Hurricane Maria on Out-migration from Puerto Rico: Evidence from Facebook Data.” Population and Development Review 45(3):617–30.  

Alexander, Monica, Kivan Polimis, and Emilio Zagheni. 2020. “Combining Social Media and Survey Data to Nowcast Migrant Stocks in the United States.” Population Research and Policy Review. doi: 10.1007/s11113-020-09599-3.

Cesare, Nina, Christan Grant, Quynh Nguyen, Hedwig Lee, and Elaine O. Nsoesie. 2018. “How Well Can Machine Learning Predict Demographics of Social Media Users?” ArXiv:1702.01807 [Cs].  

Cesare, Nina, Christan Grant, and Elaine O. Nsoesie. 2019. “Understanding Demographic Bias and Representation in Social Media Health Data.” Pp. 7–9 in Companion Publication of the 10th ACM Conference on Web Science. Boston Massachusetts USA: ACM.  

Cesare, Nina, Hedwig Lee, Tyler McCormick, Emma Spiro, and Emilio Zagheni. 2018. “Promises and Pitfalls of Using Digital Traces for Demographic Research.” Demography 55(5):1979–99.

Feehan, Dennis M., and Curtiss Cobb. 2019. “Using an Online Sample to Estimate the Size of an Offline Population.” Demography 56(6):2377–92.  

Freelon, Deen. 2018. “Computational Research in the Post-API Age.” Political Communication 35(4):665–68.  

]

.font60.pull-right[

Hess, Chris, and Sarah Chasins. n.d. “Estimating Neighborhood Rents with Scraped Data.” Retrieved May 10, 2020 (https://hesscl.com/smooth-sea/manuscript/index.html).

Kennedy, Ian, Chris Hess, Amandalynne Paullada, and Sarah Chasins. 2020. “Racialized Discourse in Seattle Rental Ad Texts.” Social Forces (soaa075). doi: 10.1093/sf/soaa075.

Mazzoli, Mattia, Boris Diechtiareff, Antònia Tugores, Willian Wives, Natalia Adler, Pere Colet, and José J. Ramasco. 2020. “Migrant Mobility Flows Characterized with Digital Data.” PLOS ONE 15(3):e0230264.  

Phillips, Nolan E., Brian L. Levy, Robert J. Sampson, Mario L. Small, and Ryan Q. Wang. 2019. “The Social Integration of American Cities: Network Measures of Connectedness Based on Everyday Mobility Across Neighborhoods.” Sociological Methods &amp; Research.  

Salganik, Matthew J. 2017. Bit by Bit: Social Research in the Digital Age. Princeton University Press.  

Zagheni, Emilio, Venkata Rama Kiran Garimella, Ingmar Weber, and Bogdan State. 2014. “Inferring International and Internal Migration Patterns from Twitter Data.” Pp. 439–444 in Proceedings of the 23rd International Conference on World Wide Web, WWW ’14 Companion. New York, NY, USA: ACM.  

Zagheni, Emilio, Ingmar Weber, and Krishna Gummadi. 2017. “Leveraging Facebook’s Advertising Platform to Monitor Stocks of Migrants.” Population and Development Review.

]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "tomorrow",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
